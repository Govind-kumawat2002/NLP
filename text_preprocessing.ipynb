{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence = \"Ram is <br>/<brShayam <!-- Remove HTMl Tags -->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTMl Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(sentence):\n",
    "    clean_text = re.sub(r'<.*?>', '', sentence)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_tags(sentence=sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove url Tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Ram is <br>/<brShayam <!--  https://www.youtube.com/watch?v=6C0sLtw5ctc&list=PLKnIA16_RmvZo7fp5kkIth6nRTeQQsjfX&index=4&ab_channel=CampusX Remove HTMl Tags -->\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    clean_text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_url=remove_urls(text=sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_html_tags(sentence=remove_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punctu=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunctuation(text):\n",
    "    for x in punctu:\n",
    "        text=text.replace(x,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removepunctuation(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat word Treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I donâ€™t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"donâ€™t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chat_words(text):\n",
    "    words = text.split()\n",
    "    normalized_words = [chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(normalized_words)\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"omg idk what u r talking about lol\"\n",
    "normalized_text = normalize_chat_words(chat_text)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_text = \"omg idk what u r talking about lol\"\n",
    "word=chat_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Chat word dictionary\n",
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I donâ€™t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"donâ€™t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}\n",
    "\n",
    "def normalize_chat_words(text):\n",
    "    words = text.split()\n",
    "    normalized_words = [chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(normalized_words)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"omg idk wht u r tlking abut lol\"\n",
    "normalized_text = normalize_chat_words(chat_text)\n",
    "corrected_text = correct_spelling(normalized_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Normalized:\", normalized_text)\n",
    "print(\"Corrected:\", corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Chat word dictionary\n",
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I donâ€™t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"donâ€™t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}\n",
    "\n",
    "def normalize_chat_words(text):\n",
    "    \"\"\"Replaces chat words with full forms\"\"\"\n",
    "    words = text.split()\n",
    "    normalized_words = [chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(normalized_words)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling using TextBlob\"\"\"\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Removes stop words from text\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"omg idk wht u r tlking abut lol but it's so funny\"\n",
    "normalized_text = normalize_chat_words(chat_text)\n",
    "corrected_text = correct_spelling(normalized_text)\n",
    "cleaned_text = remove_stop_words(corrected_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Normalized:\", normalized_text)\n",
    "print(\"Corrected:\", corrected_text)\n",
    "print(\"Without Stop Words:\", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Chat word dictionary\n",
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I donâ€™t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"donâ€™t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}\n",
    "\n",
    "def normalize_chat_words(text):\n",
    "    \"\"\"Replaces chat words with full forms\"\"\"\n",
    "    words = text.split()\n",
    "    normalized_words = [chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(normalized_words)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling using TextBlob\"\"\"\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Removes stop words from text\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"Removes emojis from text using the emoji library\"\"\"\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"omg idk wht u r tlking abut lol ðŸ˜‚ but it's so funny ðŸ¤£\"\n",
    "normalized_text = normalize_chat_words(chat_text)\n",
    "corrected_text = correct_spelling(normalized_text)\n",
    "cleaned_text = remove_stop_words(corrected_text)\n",
    "final_text = remove_emojis(cleaned_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Normalized:\", normalized_text)\n",
    "print(\"Corrected:\", corrected_text)\n",
    "print(\"Without Stop Words:\", cleaned_text)\n",
    "print(\"Final Text (No Emojis):\", final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Code with Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: omg idk wht u r tlking abut lol ðŸ˜‚ but it's so funny ðŸ¤£\n",
      "Normalized: oh my god I donâ€™t know wht you are tlking abut laugh out loud ðŸ˜‚ but it's so funny ðŸ¤£\n",
      "Corrected: oh my god I donâ€™t know who you are taking but laugh out loud ðŸ˜‚ but it's so funny ðŸ¤£\n",
      "Without Stop Words: oh god donâ€™t know taking laugh loud ðŸ˜‚ funny ðŸ¤£\n",
      "Tokenized Text: ['omg', 'idk', 'wht', 'u', 'r', 'tlking', 'abut', 'lol', 'ðŸ˜‚', 'but', 'it', \"'s\", 'so', 'funny', 'ðŸ¤£']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kumaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kumaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "# import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Chat word dictionary\n",
    "chat_word_dict = {\n",
    "    \"u\": \"you\",\n",
    "    \"r\": \"are\",\n",
    "    \"b4\": \"before\",\n",
    "    \"gr8\": \"great\",\n",
    "    \"l8r\": \"later\",\n",
    "    \"idk\": \"I donâ€™t know\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"ttyl\": \"talk to you later\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gonna\": \"going to\",\n",
    "    \"lemme\": \"let me\",\n",
    "    \"dunno\": \"donâ€™t know\",\n",
    "    \"thx\": \"thanks\",\n",
    "    \"pls\": \"please\",\n",
    "    \"ppl\": \"people\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"rofl\": \"rolling on the floor laughing\",\n",
    "    \"afk\": \"away from keyboard\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"gtg\": \"got to go\",\n",
    "    \"jk\": \"just kidding\",\n",
    "    \"hbu\": \"how about you\",\n",
    "    \"ily\": \"I love you\",\n",
    "    \"ttys\": \"talk to you soon\"\n",
    "}\n",
    "\n",
    "def normalize_chat_words(text):\n",
    "    \"\"\"Replaces chat words with full forms\"\"\"\n",
    "    words = text.split()\n",
    "    normalized_words = [chat_word_dict.get(word.lower(), word) for word in words]\n",
    "    return \" \".join(normalized_words)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling using TextBlob\"\"\"\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Removes stop words from text\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# def remove_emojis(text):\n",
    "#     \"\"\"Removes emojis from text using the emoji library\"\"\"\n",
    "#     return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Tokenizes text into words\"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"omg idk wht u r tlking abut lol ðŸ˜‚ but it's so funny ðŸ¤£\"\n",
    "normalized_text = normalize_chat_words(chat_text)\n",
    "corrected_text = correct_spelling(normalized_text)\n",
    "cleaned_text = remove_stop_words(corrected_text)\n",
    "# final_text = remove_emojis(cleaned_text)\n",
    "\n",
    "# Tokenize the final text\n",
    "tokens = tokenize_text(chat_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Normalized:\", normalized_text)\n",
    "print(\"Corrected:\", corrected_text)\n",
    "print(\"Without Stop Words:\", cleaned_text)\n",
    "# print(\"Final Text (No Emojis):\", final_text)\n",
    "print(\"Tokenized Text:\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code with Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: running runs runner easily easier\n",
      "Stemmed: run run runner easili easier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kumaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    \"\"\"Stems words in the text using Porter Stemmer\"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"running runs runner easily easier\"\n",
    "stemmed_text = stem_text(chat_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Stemmed:\", stemmed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kumaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kumaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: running runs runner easily better\n",
      "Lemmatized: run run runner easily better\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"Lemmatizes words in the text using WordNet Lemmatizer\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]  # 'pos' for verb lemmatization\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "# Example usage\n",
    "chat_text = \"running runs runner easily better\"\n",
    "lemmatized_text = lemmatize_text(chat_text)\n",
    "\n",
    "print(\"Original:\", chat_text)\n",
    "print(\"Lemmatized:\", lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
